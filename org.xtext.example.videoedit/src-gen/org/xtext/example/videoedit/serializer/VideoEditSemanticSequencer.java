/*
 * generated by Xtext 2.33.0
 */
package org.xtext.example.videoedit.serializer;

import com.google.inject.Inject;
import java.util.Set;
import org.eclipse.emf.ecore.EObject;
import org.eclipse.emf.ecore.EPackage;
import org.eclipse.xtext.Action;
import org.eclipse.xtext.Parameter;
import org.eclipse.xtext.ParserRule;
import org.eclipse.xtext.serializer.ISerializationContext;
import org.eclipse.xtext.serializer.acceptor.SequenceFeeder;
import org.eclipse.xtext.serializer.sequencer.AbstractDelegatingSemanticSequencer;
import org.eclipse.xtext.serializer.sequencer.ITransientValueService.ValueTransient;
import org.xtext.example.videoedit.services.VideoEditGrammarAccess;
import org.xtext.example.videoedit.videoEdit.AudioLevel;
import org.xtext.example.videoedit.videoEdit.Clip;
import org.xtext.example.videoedit.videoEdit.Project;
import org.xtext.example.videoedit.videoEdit.TimeCode;
import org.xtext.example.videoedit.videoEdit.Track;
import org.xtext.example.videoedit.videoEdit.VideoEditPackage;

@SuppressWarnings("all")
public class VideoEditSemanticSequencer extends AbstractDelegatingSemanticSequencer {

	@Inject
	private VideoEditGrammarAccess grammarAccess;
	
	@Override
	public void sequence(ISerializationContext context, EObject semanticObject) {
		EPackage epackage = semanticObject.eClass().getEPackage();
		ParserRule rule = context.getParserRule();
		Action action = context.getAssignedAction();
		Set<Parameter> parameters = context.getEnabledBooleanParameters();
		if (epackage == VideoEditPackage.eINSTANCE)
			switch (semanticObject.eClass().getClassifierID()) {
			case VideoEditPackage.AUDIO_LEVEL:
				sequence_AudioLevel(context, (AudioLevel) semanticObject); 
				return; 
			case VideoEditPackage.CLIP:
				sequence_Clip(context, (Clip) semanticObject); 
				return; 
			case VideoEditPackage.PROJECT:
				sequence_Project(context, (Project) semanticObject); 
				return; 
			case VideoEditPackage.TIME_CODE:
				sequence_TimeCode(context, (TimeCode) semanticObject); 
				return; 
			case VideoEditPackage.TRACK:
				sequence_Track(context, (Track) semanticObject); 
				return; 
			}
		if (errorAcceptor != null)
			errorAcceptor.accept(diagnosticProvider.createInvalidContextOrTypeDiagnostic(semanticObject, context));
	}
	
	/**
	 * <pre>
	 * Contexts:
	 *     AudioLevel returns AudioLevel
	 *
	 * Constraint:
	 *     level=INT
	 * </pre>
	 */
	protected void sequence_AudioLevel(ISerializationContext context, AudioLevel semanticObject) {
		if (errorAcceptor != null) {
			if (transientValues.isValueTransient(semanticObject, VideoEditPackage.Literals.AUDIO_LEVEL__LEVEL) == ValueTransient.YES)
				errorAcceptor.accept(diagnosticProvider.createFeatureValueMissing(semanticObject, VideoEditPackage.Literals.AUDIO_LEVEL__LEVEL));
		}
		SequenceFeeder feeder = createSequencerFeeder(context, semanticObject);
		feeder.accept(grammarAccess.getAudioLevelAccess().getLevelINTTerminalRuleCall_1_0(), semanticObject.getLevel());
		feeder.finish();
	}
	
	
	/**
	 * <pre>
	 * Contexts:
	 *     Clip returns Clip
	 *
	 * Constraint:
	 *     (
	 *         name=STRING 
	 *         source=STRING 
	 *         sourceIn=TimeCode 
	 *         sourceOut=TimeCode 
	 *         targetPosition=TimeCode 
	 *         audioLevel=AudioLevel? 
	 *         syncWith=[Clip|STRING]?
	 *     )
	 * </pre>
	 */
	protected void sequence_Clip(ISerializationContext context, Clip semanticObject) {
		genericSequencer.createSequence(context, semanticObject);
	}
	
	
	/**
	 * <pre>
	 * Contexts:
	 *     Project returns Project
	 *
	 * Constraint:
	 *     (name=STRING tracks+=Track*)
	 * </pre>
	 */
	protected void sequence_Project(ISerializationContext context, Project semanticObject) {
		genericSequencer.createSequence(context, semanticObject);
	}
	
	
	/**
	 * <pre>
	 * Contexts:
	 *     TimeCode returns TimeCode
	 *
	 * Constraint:
	 *     (hours=INT minutes=INT seconds=INT frames=INT)
	 * </pre>
	 */
	protected void sequence_TimeCode(ISerializationContext context, TimeCode semanticObject) {
		if (errorAcceptor != null) {
			if (transientValues.isValueTransient(semanticObject, VideoEditPackage.Literals.TIME_CODE__HOURS) == ValueTransient.YES)
				errorAcceptor.accept(diagnosticProvider.createFeatureValueMissing(semanticObject, VideoEditPackage.Literals.TIME_CODE__HOURS));
			if (transientValues.isValueTransient(semanticObject, VideoEditPackage.Literals.TIME_CODE__MINUTES) == ValueTransient.YES)
				errorAcceptor.accept(diagnosticProvider.createFeatureValueMissing(semanticObject, VideoEditPackage.Literals.TIME_CODE__MINUTES));
			if (transientValues.isValueTransient(semanticObject, VideoEditPackage.Literals.TIME_CODE__SECONDS) == ValueTransient.YES)
				errorAcceptor.accept(diagnosticProvider.createFeatureValueMissing(semanticObject, VideoEditPackage.Literals.TIME_CODE__SECONDS));
			if (transientValues.isValueTransient(semanticObject, VideoEditPackage.Literals.TIME_CODE__FRAMES) == ValueTransient.YES)
				errorAcceptor.accept(diagnosticProvider.createFeatureValueMissing(semanticObject, VideoEditPackage.Literals.TIME_CODE__FRAMES));
		}
		SequenceFeeder feeder = createSequencerFeeder(context, semanticObject);
		feeder.accept(grammarAccess.getTimeCodeAccess().getHoursINTTerminalRuleCall_0_0(), semanticObject.getHours());
		feeder.accept(grammarAccess.getTimeCodeAccess().getMinutesINTTerminalRuleCall_2_0(), semanticObject.getMinutes());
		feeder.accept(grammarAccess.getTimeCodeAccess().getSecondsINTTerminalRuleCall_4_0(), semanticObject.getSeconds());
		feeder.accept(grammarAccess.getTimeCodeAccess().getFramesINTTerminalRuleCall_6_0(), semanticObject.getFrames());
		feeder.finish();
	}
	
	
	/**
	 * <pre>
	 * Contexts:
	 *     Track returns Track
	 *
	 * Constraint:
	 *     (type=TrackType name=ID clips+=Clip*)
	 * </pre>
	 */
	protected void sequence_Track(ISerializationContext context, Track semanticObject) {
		genericSequencer.createSequence(context, semanticObject);
	}
	
	
}
